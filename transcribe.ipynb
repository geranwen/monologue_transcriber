{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor\n",
    "# import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "model_id = \"openai/whisper-large-v3\"\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    max_new_tokens=128,\n",
    "    chunk_length_s=30,\n",
    "    batch_size=16,\n",
    "    return_timestamps=True,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\mono_transcribe_2\\Lib\\site-packages\\transformers\\models\\whisper\\modeling_whisper.py:697: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n"
     ]
    }
   ],
   "source": [
    "result = pipe('media/DJI_0234_CH.mp3',return_timestamps=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'timestamp': (0.0, 2.0), 'text': '太厉害了'}, {'timestamp': (2.0, 4.0), 'text': '这种景色'}, {'timestamp': (4.0, 6.0), 'text': '好棒啊'}, {'timestamp': (8.0, 10.0), 'text': '那边是深圳'}, {'timestamp': (12.0, 14.0), 'text': '那边是个山头'}, {'timestamp': (16.0, 18.0), 'text': '然后这边就是香港'}, {'timestamp': (22.0, 24.0), 'text': '然后那边是大茅山'}, {'timestamp': (24.0, 27.84), 'text': '我都希望等我上去了之后'}, {'timestamp': (27.84, 30.78), 'text': '云彩都能散掉吧'}, {'timestamp': (30.78, 33.0), 'text': '现在我还在云彩下面'}, {'timestamp': (33.0, 36.28), 'text': '今天的云彩其实没有很高啊'}, {'timestamp': (36.28, 38.0), 'text': '都在狮子山以下嘛'}, {'timestamp': (42.0, 44.28), 'text': '狮子山要低很多'}, {'timestamp': (44.28, 46.6), 'text': '好厉害'}, {'timestamp': (50.6, 52.6), 'text': '这次很累'}, {'timestamp': (52.6, 54.6), 'text': '一千米'}, {'timestamp': (54.6, 56.6), 'text': '我也没有爬真的爬一千米'}, {'timestamp': (56.6, 58.6), 'text': '但是'}, {'timestamp': (67.44, 70.16), 'text': '还是有点累的天哪'}, {'timestamp': (70.16, 73.2), 'text': '我腿又软了'}, {'timestamp': (73.2, 74.74), 'text': 'I need calories'}, {'timestamp': (74.74, 77.94), 'text': '那个香蕉我要是带了就好了'}, {'timestamp': (77.94, 80.2), 'text': 'But yeah, this is amazing'}, {'timestamp': (80.2, 81.84), 'text': 'This is a fantastic trail'}, {'timestamp': (81.84, 91.52), 'text': '上下的路应该就好走很多了这一段路这边是什么动物这条路太棒了'}, {'timestamp': (107.0, 109.0), 'text': '这是什么动物我的天哪我出好多汗了'}, {'timestamp': (109.0, 112.0), 'text': '我以后爬山要戴个帽子之类的'}, {'timestamp': (112.0, 114.0), 'text': 'Jesus'}, {'timestamp': (123.0, 125.16), 'text': '继续爬吧'}, {'timestamp': (125.16, 126.64), 'text': '天哪'}, {'timestamp': (126.64, 132.12), 'text': '我希望云才能退下去'}, {'timestamp': (132.12, 134.0), 'text': '否则的话'}, {'timestamp': (134.0, 136.6), 'text': '到上面都没意思不是吗'}, {'timestamp': (136.6, 139.34), 'text': '可能还不如去爬十字山呢'}, {'timestamp': (139.34, 141.9), 'text': '不过十字山其实也没多高'}, {'timestamp': (141.9, 146.78), 'text': '走一段'}, {'timestamp': (146.78, 148.46), 'text': '然后再吃个能量棒吧'}, {'timestamp': (148.46, 150.4), 'text': '我的天哪'}, {'timestamp': (150.4, 151.5), 'text': '那儿呢'}, {'timestamp': (151.5, 152.04), 'text': '水库'}, {'timestamp': (152.04, 154.76), 'text': '我之前还说要去'}, {'timestamp': (154.76, 157.16), 'text': '我的天'}, {'timestamp': (157.16, 165.24), 'text': '那边应该是沙田那边吧'}, {'timestamp': (165.24, 167.0), 'text': 'Jesus Christ'}, {'timestamp': (167.0, 168.8), 'text': 'Fucking hell'}, {'timestamp': (168.8, 169.98), 'text': '那儿呢 天文台'}, {'timestamp': (169.98, 171.32), 'text': '大茂山'}, {'timestamp': (171.32, 174.24), 'text': 'Fucking hell'}, {'timestamp': (174.24, 178.22), 'text': \"I'll take a break\"}, {'timestamp': (180.08, 181.08), 'text': 'Fucking hell'}]\n"
     ]
    }
   ],
   "source": [
    "print(result[\"chunks\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mono_transcribe_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
